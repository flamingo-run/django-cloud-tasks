{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Django Cloud Tasks!","text":"<p>Django Cloud Tasks is your go-to Django app for effortlessly running asynchronous tasks on Google Cloud Platform. It makes it a breeze to work with Google Cloud Tasks, Cloud Scheduler, and Cloud Pub/Sub right from your Django project.</p> <p>Think of it as a way to offload heavy work (like image processing or report generation), schedule future jobs (like nightly cleanups), or react to events in a decoupled way (like sending a welcome email when a new user signs up) \u2013 all without making your users wait or bogging down your web servers.</p> <p>This documentation will guide you through setting up and using its powerful features.</p>"},{"location":"#installation","title":"Installation","text":"<p>Getting this bad boy into your project is super easy. Just pip install it:</p> <pre><code>pip install django-cloud-tasks\n</code></pre>"},{"location":"#django-setup","title":"Django Setup","text":"<ol> <li>Add <code>'django_cloud_tasks'</code> to your <code>INSTALLED_APPS</code> in <code>settings.py</code>:</li> </ol> settings.py<pre><code>INSTALLED_APPS = [\n    # ...\n    'django_cloud_tasks',\n    # ...\n]\n</code></pre> <ol> <li>Include the Django Cloud Tasks URLs in your main <code>urls.py</code>. These URLs are the endpoints that Google Cloud services will call to trigger your tasks.</li> </ol> urls.py<pre><code>from django.urls import path, include\n\nurlpatterns = [\n    # ... other urls\n    path('my-tasks-prefix/', include('django_cloud_tasks.urls')),\n    # ...\n]\n</code></pre> <ol> <li>Make sure this endpoint is publicly accessible if you're not running in a private VPC, as Google Cloud services need to reach it.</li> </ol>"},{"location":"#required-google-cloud-apis","title":"Required Google Cloud APIs","text":"<p>To use <code>django-cloud-tasks</code> effectively, you'll need to enable the following APIs in your Google Cloud Project:</p> <ul> <li>Cloud Tasks API</li> <li>Cloud Scheduler API</li> <li>Pub/Sub API</li> <li>Optional: Admin SDK API (Needed for some advanced features or if you are working with domain-wide delegation for service accounts, though typically not required for basic task and pub/sub operations with OIDC or standard service account authentication).</li> </ul>"},{"location":"#core-configuration-settingspy","title":"Core Configuration (<code>settings.py</code>)","text":"<p>You can tweak how Django Cloud Tasks behaves through your Django <code>settings.py</code> file. All settings are prefixed with <code>DJANGO_CLOUD_TASKS_</code>. You can also set these as environment variables (which will take precedence if both are set).</p> <p>Here are some of the main ones to get you started:</p> <ul> <li> <p><code>DJANGO_CLOUD_TASKS_ENDPOINT</code>: The full base URL of your application (e.g., <code>https://your-cool-app.com</code>). This is crucial because Cloud Tasks, Scheduler, and Pub/Sub push subscriptions need to know the exact URL to send HTTP requests to trigger your tasks. It's often your Cloud Run service URL.</p> <ul> <li>Default: <code>\"http://localhost:8080\"</code></li> <li>Example: <code>DJANGO_CLOUD_TASKS_ENDPOINT = \"https://myapp.com\"</code></li> </ul> </li> <li> <p><code>DJANGO_CLOUD_TASKS_APP_NAME</code>: A unique name for your application or service. This is used to prefix and organize resources in GCP, such as Cloud Scheduler job names or Pub/Sub topic/subscription names, making it easier to manage them, especially if you have multiple applications in the same GCP project.</p> <ul> <li>Default: <code>None</code> (reads from <code>APP_NAME</code> environment variable if set)</li> <li>Example: <code>DJANGO_CLOUD_TASKS_APP_NAME = \"user-service\"</code></li> </ul> </li> <li> <p><code>DJANGO_CLOUD_TASKS_EAGER</code>: If set to <code>True</code>, tasks will run synchronously (i.e., immediately in the same process) instead of being sent to Google Cloud. This is incredibly useful for local development and testing, as it bypasses the need for GCP setup and lets you debug tasks like regular function calls.</p> <ul> <li>Default: <code>False</code></li> <li>Example: <code>DJANGO_CLOUD_TASKS_EAGER = settings.DEBUG</code> # (1)</li> </ul> </li> <li> <p><code>DJANGO_CLOUD_TASKS_URL_NAME</code>: The specific Django URL name (not path) within the included <code>django_cloud_tasks.urls</code> that is used as the endpoint for on-demand tasks triggered by Cloud Tasks and scheduled tasks triggered by Cloud Scheduler.</p> <ul> <li>Default: <code>\"tasks-endpoint\"</code></li> </ul> </li> <li> <p><code>DJANGO_CLOUD_TASKS_DELIMITER</code>: A string used to join parts of names, for example, when constructing default queue names, scheduler job names, or Pub/Sub topic/subscription names (e.g., <code>my-app--my-task</code>).</p> <ul> <li>Default: <code>\"--\"</code></li> </ul> </li> <li> <p>Header Propagation: Settings related to header propagation are covered in detail in the \"Header Propagation\" section.</p> </li> </ul> <p>There are more settings for fine-tuning retries, Pub/Sub behavior, and specific service interactions. We'll touch upon many of these in the relevant sections. For a comprehensive list, you can always refer to the <code>django_cloud_tasks.apps.DjangoCloudTasksAppConfig</code> class.</p> <p>With this foundational setup, you're ready to dive into defining and using the different types of tasks! </p>"},{"location":"headers/","title":"Header Propagation","text":"<p>When you're dealing with asynchronous tasks, especially in a microservices or distributed environment, it's often crucial to carry over some context from the initial request that triggered the task. Header propagation allows you to do just that.</p>"},{"location":"headers/#why-propagate-headers","title":"Why Propagate Headers?","text":"<p>Common use cases include:</p> <ul> <li>Distributed Tracing: To track a single logical operation as it flows through multiple services or asynchronous tasks. Headers like <code>traceparent</code> (as used by OpenTelemetry and others) or <code>X-Cloud-Trace-Context</code> (used by Google Cloud) are prime candidates.</li> <li>Tenant/User Context: If you have a multi-tenant application, you might want to propagate a <code>X-Tenant-ID</code> or <code>X-User-ID</code> so the task execution environment knows which tenant's data to operate on or which user initiated the action (primarily for logging or non-security-sensitive context).</li> <li>Feature Flags or A/B Testing Context: Propagating headers related to feature flags or A/B testing variants can ensure consistent behavior in asynchronous tasks.</li> <li>Client Information: Propagating <code>User-Agent</code> or custom client version headers (<code>X-Client-Version</code>) for logging and debugging purposes.</li> </ul>"},{"location":"headers/#how-it-works","title":"How It Works","text":"<p>Header propagation relies on middleware to manage context:</p> <ol> <li>Capture: The <code>HeadersContextMiddleware</code> intercepts incoming Django requests, extracts headers specified in <code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS</code>, and stores them in a request-local context.</li> <li>Forwarding:<ul> <li>Cloud Tasks (On-Demand/Scheduled): When a task is pushed, these stored headers are added as HTTP headers to the request Cloud Tasks (or Cloud Scheduler) makes to your application.</li> <li>Pub/Sub (PublisherTask): Propagated headers are embedded as a dictionary within the JSON payload of the Pub/Sub message, under the key defined by <code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS_KEY</code>.</li> </ul> </li> <li>Retrieval:<ul> <li>Cloud Tasks: Within your <code>Task</code> or <code>PeriodicTask</code>, <code>self._metadata.custom_headers</code> provides access to these propagated HTTP headers.</li> <li>Pub/Sub: The <code>PubSubHeadersMiddleware</code> extracts the embedded headers from the message payload when a push request for a <code>SubscriberTask</code> arrives. Your <code>SubscriberTask</code> then typically accesses them from the message <code>content</code> dictionary.</li> </ul> </li> </ol>"},{"location":"headers/#configuration","title":"Configuration","text":""},{"location":"headers/#1-middleware-setup","title":"1. Middleware Setup","text":"<p>To enable header propagation, you must add the relevant middleware to your <code>settings.py</code>:</p> <pre><code>MIDDLEWARE = [\n    # ... other django middleware ...\n    'django_cloud_tasks.middleware.HeadersContextMiddleware', # (1)\n    'django_cloud_tasks.middleware.PubSubHeadersMiddleware', # (2)\n    # ... other app middleware ...\n]\n</code></pre> <ol> <li>Essential for capturing headers from incoming Django requests and making them available for propagation. Also helps make headers available within a task's execution if they were propagated by Cloud Tasks.</li> <li> <p>Specifically for tasks triggered by Pub/Sub push subscriptions. It extracts headers embedded in the Pub/Sub message body.</p> </li> <li> <p><code>HeadersContextMiddleware</code>: Essential for capturing headers from incoming Django requests and making them available for propagation when new tasks are initiated. It also helps make headers available within a task's execution if they were propagated by Cloud Tasks.</p> </li> <li><code>PubSubHeadersMiddleware</code>: Specifically for tasks triggered by Pub/Sub push subscriptions. It extracts headers that were embedded in the Pub/Sub message body by a <code>PublisherTask</code> and loads them into the Django request context for the subscriber task handler.</li> </ol>"},{"location":"headers/#2-settings-for-propagation","title":"2. Settings for Propagation","text":"<p>You configure which headers are propagated and how they are keyed in Pub/Sub messages via your Django <code>settings.py</code>:</p> <ul> <li> <p><code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS</code>: A list of HTTP header names that you want to capture and propagate. The matching from incoming requests is case-insensitive.</p> <ul> <li>Default: <code>[\"traceparent\"]</code></li> <li>Example:     <pre><code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS = [\n    \"traceparent\",\n    \"X-Request-ID\",\n    \"X-Tenant-ID\",\n    \"X-User-ID\",\n    \"Accept-Language\",\n]\n</code></pre></li> </ul> </li> <li> <p><code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS_KEY</code> (For Pub/Sub <code>PublisherTask</code> / <code>SubscriberTask</code>):     This setting defines the key within the JSON message body where the dictionary of propagated headers will be stored by <code>PublisherTask</code> and read from by <code>PubSubHeadersMiddleware</code> (and your <code>SubscriberTask</code>).</p> <ul> <li>Default: <code>\"_http_headers\"</code></li> <li>Example:     <pre><code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS_KEY = \"_propagated_context_headers\"\n</code></pre></li> </ul> </li> </ul>"},{"location":"headers/#accessing-propagated-headers","title":"Accessing Propagated Headers","text":""},{"location":"headers/#tasks","title":"Tasks","text":"<p>These tasks are executed via an HTTP request from Google Cloud Tasks/Scheduler. Propagated headers are part of this request.</p> <p>Access them via <code>self._metadata.custom_headers</code> in your task's <code>run</code> method. This dictionary holds headers from the task execution request that were listed in <code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS</code>.</p> <pre><code>from django_cloud_tasks.tasks import Task\n\n\nclass ProcessDataWithTraceTask(Task):\n    def run(self, data_id: int):\n        trace_id = self._metadata.custom_headers.get(\"traceparent\") # (1)\n        tenant_id = self._metadata.custom_headers.get(\"x-tenant-id\")\n\n        print(f\"Executing for data ID: {data_id}, Trace: {trace_id}, Tenant: {tenant_id}\")\n        # ... your task logic ...\n</code></pre> <ol> <li>Headers in <code>custom_headers</code> are typically lowercased by the web server/Django.</li> </ol>"},{"location":"headers/#pubsub","title":"Pub/Sub","text":"<p>With <code>PublisherTask</code>, headers are embedded in the Pub/Sub message body. Your <code>SubscriberTask</code> accesses them from the <code>content</code> dictionary using the <code>DJANGO_CLOUD_TASKS_PROPAGATED_HEADERS_KEY</code>.</p> <pre><code>from django_cloud_tasks.tasks import SubscriberTask\nfrom django_cloud_tasks.tasks.helpers import get_app # (1)\n\nclass AuditLogSubscriber(SubscriberTask):\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"user-activity-events\"\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None):\n        headers_key = get_app().propagated_headers_key # (2)\n        propagated_headers = content.get(headers_key, {}) # (3)\n\n        user_id = propagated_headers.get(\"X-User-ID\") # (4)\n        request_id = propagated_headers.get(\"X-Request-ID\")\n\n        print(f\"Audit event: {content}, User: {user_id}, Request: {request_id}\")\n        # ... audit logging ...\n</code></pre> <ol> <li>Helper to get the app config, useful for accessing settings like <code>propagated_headers_key</code> dynamically.</li> <li>Get the configured key for propagated headers.</li> <li>Safely retrieve the dictionary of propagated headers from the message content.</li> <li>Access specific headers. The case here matches how they were put into the dictionary by <code>PublisherTask</code>.</li> </ol> <p>By correctly setting up the middleware and configurations, header propagation provides valuable context for your asynchronous operations.</p>"},{"location":"on_demand_tasks/","title":"On-Demand Tasks","text":"<p>On-demand tasks are your workhorses for anything you want to do asynchronously. Think of sending a welcome email after a user signs up, processing an image after upload, or calling a slow external API without making your user wait. These tasks are pushed to a Google Cloud Tasks queue and executed by an HTTP request back to your Django application.</p>"},{"location":"on_demand_tasks/#defining-a-basic-task","title":"Defining a Basic Task","text":"<p>Creating a task is as simple as inheriting from <code>django_cloud_tasks.tasks.Task</code> and implementing the <code>run</code> method. This method contains the logic your task will execute.</p> <p>Example: Sending a Welcome Email</p> <p>Let's say you want to send a welcome email to a new user. Their details (like email and name) will be passed as arguments to the task.</p> users/tasks.py<pre><code>from django.contrib.auth.models import User\nfrom django.core.mail import send_mail\nfrom django_cloud_tasks.tasks import Task\n\n\nclass SendWelcomeEmailTask(Task):\n    def run(self, user_id: int, custom_message: str | None = None): # (1)!\n        try:\n            user = User.objects.get(pk=user_id) # (2)!\n            subject = f\"Welcome to Our Awesome Platform, {user.first_name}!\"\n            message_body = custom_message or f\"Hi {user.first_name}, \\n\\nThanks for signing up! We're thrilled to have you.\"\n            send_mail(\n                subject=subject,\n                message=message_body,\n                from_email=\"noreply@myawesomeplatform.com\",\n                recipient_list=[user.email],\n                fail_silently=False,\n            )\n            print(f\"Welcome email sent to {user.email}\")\n            return {\"status\": \"success\", \"user_id\": user_id, \"email\": user.email}\n        except User.DoesNotExist:\n            print(f\"User with ID {user_id} not found. Cannot send welcome email.\")\n            return {\"status\": \"error\", \"reason\": \"user_not_found\"}\n        except Exception as e:\n            print(f\"Failed to send welcome email to user {user_id}: {e}\")\n            raise # (3)!\n</code></pre> <ol> <li>The <code>run</code> method is where your task's logic resides. Arguments must be JSON serializable.</li> <li>It's good practice to pass IDs and re-fetch database objects within the task.</li> <li>Re-raising a generic exception will cause Cloud Tasks to retry the task based on queue configuration.</li> </ol> <p>Task Discovery</p> <p>Django Cloud Tasks automatically discovers task classes that inherit from <code>Task</code>, <code>PeriodicTask</code>, etc. Just ensure the Python modules containing your task definitions (e.g., <code>myapp/tasks.py</code>) are imported by Django at startup. A common pattern is to import them in your app's <code>apps.py</code> within the <code>ready()</code> method.</p> <p>Serialization</p> <p>Arguments passed to your task's <code>run</code> method (and the return value) must be JSON serializable. Basic types like integers, strings, lists, and dicts are fine. For complex objects like Django model instances, you should pass identifiers (like a primary key) and re-fetch the object within the task, as shown in the <code>SendWelcomeEmailTask</code>.</p>"},{"location":"on_demand_tasks/#running-your-tasks","title":"Running Your Tasks","text":"<p>Once defined, you can trigger your tasks from anywhere in your Django code (views, signals, model methods, etc.).</p>"},{"location":"on_demand_tasks/#run-as-soon-as-possible","title":"Run As Soon As Possible","text":"<p>This is the most common way. It enqueues the task to be executed by Cloud Tasks as soon as a worker is available. The <code>kwargs</code> are the arguments to your task's <code>run</code> method.</p> <pre><code>SendWelcomeEmailTask.asap(user_id=user_id)\n\nSendWelcomeEmailTask.asap(user_id=user_id, custom_message=\"Hey there, special user!\")\n</code></pre>"},{"location":"on_demand_tasks/#schedule-for-a-specific-future-time","title":"Schedule for a Specific Future Time","text":"<p>Use this to delay a task's execution.</p> <pre><code>from datetime import timedelta\nfrom django.utils import timezone\n\n\nuser_id_to_follow_up = 123\ntask_kwargs = {\n    \"user_id\": user_id_to_follow_up,\n    \"custom_message\": \"Hope you're enjoying the platform after your first week!\",\n}\n\nSendWelcomeEmailTask.later(\n    task_kwargs=task_kwargs,\n    eta=timezone.now() + timedelta(days=7) # (1)!\n)\n\nSendWelcomeEmailTask.later(\n    task_kwargs=task_kwargs,\n    eta=30 * 60, # (2)!\n)\n</code></pre> <ol> <li>Example of scheduling a task for a specific future <code>datetime</code>.</li> <li><code>eta</code> can also be an integer representing seconds from now.</li> </ol> <p>Maximum ETA</p> <p>When using <code>eta</code>, be mindful of the <code>DJANGO_CLOUD_TASKS_MAXIMUM_ETA_TASK</code> setting (or its environment variable counterpart): this setting defines the maximum number of seconds into the future a task can be scheduled. Google Cloud Tasks itself has a limit (typically 30 days).</p> <p>If <code>DJANGO_CLOUD_TASKS_MAXIMUM_ETA_TASK</code> is set, it imposes an additional, potentially more restrictive, limit within your application. *   Default: <code>None</code> (meaning the library doesn't impose its own limit beyond GCP's). *   Example: <code>DJANGO_CLOUD_TASKS_MAXIMUM_ETA_TASK = 60 * 60 * 24 * 7</code> (limit to 7 days).</p>"},{"location":"on_demand_tasks/#run-synchronously","title":"Run Synchronously","text":"<p>Executes the task's <code>run</code> method immediately in the current process. This is the default behavior if <code>DJANGO_CLOUD_TASKS_EAGER = True</code> is set in your settings. It's extremely helpful for debugging and local development.</p> <pre><code>SendWelcomeEmailTask.sync( # (1)!\n    user_id=some_user.id,\n    custom_message=\"Testing sync call.\",\n)\n</code></pre> <ol> <li>This will run the <code>SendWelcomeEmailTask.run()</code> method directly.</li> </ol>"},{"location":"on_demand_tasks/#schedule-randomly-before-a-deadline","title":"Schedule Randomly Before a Deadline","text":"<p>Schedules the task to run at a random time between now and the specified <code>max_eta</code> (maximum execution time).</p> <p>Useful for distributing load for non-time-critical tasks. It's not a load balancer, it's just a way to schedule tasks to run at different times.</p> <pre><code>from django.utils import timezone\nfrom datetime import timedelta\n\n\nclass ProcessAnalyticsBatch(Task):\n    def run(self, user_ids: list[int]):\n        max_execution_time = timezone.now() + timedelta(hours=1)\n\n        for user_id in user_ids:\n            SendWelcomeEmailTask.until(\n                task_kwargs={\"user_id\": user_id},\n                max_eta=max_execution_time, # (1)!\n            )\n</code></pre> <ol> <li>Process a batch of optional analytics updates sometime in the next hour</li> </ol>"},{"location":"on_demand_tasks/#how-it-works-under-the-hood","title":"How It Works Under the Hood","text":"<p>When you trigger an on-demand task using methods like <code>asap()</code> or <code>later()</code>, several steps occur behind the scenes to ensure your task is processed reliably and asynchronously:</p> <ol> <li>Task Invocation: Your application code calls a task method (e.g., <code>SendWelcomeEmailTask.asap(user_id=123)</code>).</li> <li>Payload &amp; Target Construction: <code>django-cloud-tasks</code> serializes the provided arguments (e.g., <code>user_id=123</code>) into a JSON payload. It also determines the target Google Cloud Tasks queue and the specific HTTP endpoint URL within your Django application that is configured to execute this task.</li> <li>Google Cloud Tasks API Call: The library makes an authenticated API call to the Google Cloud Tasks service. This call instructs Cloud Tasks to create a new task in the designated queue. The request to GCP includes the JSON payload, the target URL, any specified ETA (for <code>.later</code>), and other execution options (like <code>only_once</code> or custom headers if using <code>push()</code>).</li> <li>Task Queuing by GCP: Google Cloud Tasks receives this request, validates it, and securely stores the task in the specified queue. The task now waits for a worker to become available or for its scheduled ETA to arrive.</li> <li>HTTP Invocation by GCP: At the appropriate time (immediately for <code>asap</code>, or after the ETA for <code>later</code>), Google Cloud Tasks makes an HTTP POST request from its infrastructure to the target URL of your Django application. This request includes the JSON payload in its body and any necessary headers (e.g., for tracing, authentication, or propagated headers).</li> <li>Task Execution in Django: Your Django application receives this incoming HTTP request. The <code>django-cloud-tasks</code> view handler, mapped via <code>django_cloud_tasks.urls</code>, processes this request. It identifies the correct task class (e.g., <code>SendWelcomeEmailTask</code>) based on the URL, deserializes the JSON payload from the request body into Python arguments, and then calls the task's <code>run()</code> method with these arguments.</li> <li>Acknowledgement to GCP: Upon successful receipt and initial processing by your Django endpoint (specifically, if the endpoint returns an HTTP 2xx status code like 200 OK or 202 Accepted), Google Cloud Tasks considers the task acknowledged and removes it from the queue (or marks it as completed, subject to retry policies if errors occurred during the <code>run</code> method that weren't handled).</li> </ol> <p>This entire process ensures that your task invocation is decoupled from its actual execution, providing benefits like resilience to temporary failures (through retries managed by Cloud Tasks) and improved application responsiveness by offloading work to background processes.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant AppCode as \"Your Application Code\"\n    participant DCTLib as \"django-cloud-tasks Library\"\n    participant GCloudTasks as \"Google Cloud Tasks Service\"\n    participant DCTView as \"django-cloud-tasks View\"\n    participant YourTaskRun as \"Your Task's .run() method\"\n\n    AppCode-&gt;&gt;DCTLib: MyTask.asap(params) / .later(params, eta)\n    DCTLib-&gt;&gt;GCloudTasks: API: Create Task (payload, target URL, queue, ETA)\n    GCloudTasks--&gt;&gt;DCTLib: Task Created (Task ID)\n\n    Note over GCloudTasks, DCTView: Later (immediately or at ETA)...\n\n    GCloudTasks-&gt;&gt;DCTView: HTTP POST (payload, headers)\n    DCTView-&gt;&gt;YourTaskRun: Deserializes payload &amp; Calls .run(params)\n    YourTaskRun-&gt;&gt;YourTaskRun: Executes your custom logic\n    YourTaskRun--&gt;&gt;DCTView: Returns result (or raises exception)\n    DCTView--&gt;&gt;GCloudTasks: HTTP 2xx (Acknowledgement) / Error</code></pre>"},{"location":"on_demand_tasks/#advanced-task-configuration","title":"Advanced Task Configuration","text":"<p>You can fine-tune task behavior using several class attributes and methods on your <code>Task</code> subclass. These configurations often map to Google Cloud Tasks API features.</p>"},{"location":"on_demand_tasks/#ensuring-uniqueness","title":"Ensuring Uniqueness","text":"<p>Set <code>only_once = True</code> on your task class if you want to prevent duplicate enqueues of tasks that are identical by class name for a given queue. Cloud Tasks will use a deterministic task name derived from your task's class name.</p> <ul> <li>Use Case: Imagine you have a task <code>ProcessOrderTask</code> that gets called when an order is submitted. If, due to a client-side retry or a race condition, your system tries to enqueue <code>ProcessOrderTask</code> for the same order multiple times in quick succession before the first one is picked up, <code>only_once = True</code> can help prevent multiple identical tasks for that order from being added to the queue initially.</li> </ul> <p>De-duplication</p> <p>This de-duplication is based on the task class name. It doesn't consider task arguments.</p> <p>If you need de-duplication based on specific arguments (e.g., \"only one <code>ProcessOrderTask</code> for <code>order_id=123</code>\"), you'd need to implement that logic yourself, perhaps by checking for an existing task with a custom-generated name via the <code>push()</code> method.</p> <pre><code>class ProcessOrderTask(Task):\n    only_once = True\n\n    def run(self, order_id: int, payment_details: dict):\n        print(f\"Processing order {order_id}...\")\n        # ... order processing logic ...\n</code></pre>"},{"location":"on_demand_tasks/#enqueue-retry-policy","title":"Enqueue Retry Policy","text":"<p>These settings control retries if the the act of trying to send the task to Google Cloud Tasks fails, for example, due to a transient network issue or a temporary problem with the Cloud Tasks API. This is not about retrying your task if its <code>run()</code> method fails.</p> <ul> <li><code>enqueue_retry_exceptions: list[str | Type[Exception]] | None</code>: A list of exception types (or their string paths like <code>'google.api_core.exceptions.ServiceUnavailable'</code>) that should trigger a retry. Defaults to an empty list (or what's set globally via <code>DJANGO_CLOUD_TASKS_ENQUEUE_RETRY_EXCEPTIONS</code>).</li> <li><code>enqueue_retry_initial: float | None</code>: Initial delay in seconds for the first retry. Defaults to global config.</li> <li><code>enqueue_retry_maximum: float | None</code>: Maximum delay in seconds between retries. Defaults to global config.</li> <li><code>enqueue_retry_multiplier: float | None</code>: Multiplier for increasing the delay between retries. Defaults to global config.</li> <li><code>enqueue_retry_deadline: float | None</code>: Total time in seconds to keep retrying. Defaults to global config.</li> </ul> <pre><code>from google.api_core.exceptions import ServiceUnavailable, InternalServerError\n\nclass RobustEnqueueTask(Task):\n    enqueue_retry_exceptions = [ServiceUnavailable, InternalServerError, \"requests.exceptions.ConnectionError\"] # (1)!\n    enqueue_retry_initial = 2.0  # (2)!\n    enqueue_retry_maximum = 60.0 # (3)!\n    enqueue_retry_multiplier = 2.5 # (4)!\n    enqueue_retry_deadline = 300.0 # (5)!\n\n    def run(self, data: dict):\n        print(\"Task enqueued robustly and now running.\")\n</code></pre> <ol> <li>List of exceptions that should trigger a retry.</li> <li>Start with a 2-second delay for retries.</li> <li>Cap retries at 1-minute intervals.</li> <li>Multiply the delay by 2.5 each time.</li> <li>Try for up to 5 minutes in total.</li> </ol>"},{"location":"on_demand_tasks/#using-custom-queue-names","title":"Using Custom Queue Names","text":"<p>By default, tasks are sent to a queue named after your <code>DJANGO_CLOUD_TASKS_APP_NAME</code> (or just <code>\"tasks\"</code> if <code>APP_NAME</code> is not set). You can direct specific tasks to different queues by overriding the <code>queue()</code> class method. This is useful for prioritizing tasks or managing different workloads (e.g., short, quick tasks vs. long-running batch jobs).</p> <p>Make sure any custom queues you specify actually exist in your Google Cloud Tasks project.</p> <pre><code>class HighPriorityNotification(Task):\n    @classmethod\n    def queue(cls) -&gt; str:\n        return \"critical-notifications-queue\"\n\n    def run(self, user_id: int, alert_message: str):\n        # ... send an urgent alert ...\n        print(f\"Sent high priority alert to user {user_id}\")\n\n\nclass BatchDataProcessing(Task):\n    @classmethod\n    def queue(cls) -&gt; str:\n        return \"batch-jobs-queue\"\n\n    def run(self, dataset_id: str):\n        # ... process a large dataset ...\n        print(f\"Processed batch data for {dataset_id}\")\n</code></pre>"},{"location":"on_demand_tasks/#suggesting-a-task-timeout","title":"Suggesting a Task Timeout","text":"<p>Cloud Tasks need to know how long to wait for your task to complete before considering it timed out. You can suggest a timeout by overriding <code>get_task_timeout()</code>. The actual timeout is ultimately controlled by the queue configuration in GCP, but this provides a hint.</p> <pre><code>from datetime import timedelta\n\n\nclass ReportGenerationTask(Task):\n    @classmethod\n    def get_task_timeout(cls) -&gt; timedelta | None:\n        return timedelta(minutes=15) # (1)!\n\n    def run(self, report_params: dict):\n        # ... logic to generate a potentially long report ...\n        print(\"Report generation complete.\")\n</code></pre> <ol> <li>This report can sometimes take a while; suggest Cloud Tasks allow up to 15 minutes.</li> </ol>"},{"location":"on_demand_tasks/#accessing-task-metadata","title":"Accessing Task Metadata","text":"<p>Inside your task's <code>run</code> method, you can access information about the current execution attempt via <code>self._metadata</code>. This is an instance of <code>TaskMetadata</code> (or your custom class specified by <code>DJANGO_CLOUD_TASKS_TASK_METADATA_CLASS</code>).</p> <ul> <li>Use Case: You might want to log the attempt number, or have slightly different behavior on the first attempt versus a retry (e.g., more aggressive external API calls on first try, then back off).</li> </ul> <pre><code>class RetryAwareTask(Task):\n    def run(self, api_call_details: dict):\n        print(f\"--- Task Execution --- \")\n        print(f\"Task ID: {self._metadata.task_id}\")\n        print(f\"Queue: {self._metadata.queue_name}\")\n        print(f\"Attempt Number (dispatch count + 1): {self._metadata.attempt_number}\") # (1)\n        print(f\"Execution Number (non-5XX responses): {self._metadata.execution_number}\") # (2)\n        print(f\"Scheduled ETA: {self._metadata.eta}\")\n\n        if self._metadata.previous_failure: # (3)\n            print(f\"This task previously failed with reason: {self._metadata.previous_failure}\")\n\n        if self._metadata.is_cloud_scheduler: # (4)\n             print(f\"This task was triggered by Cloud Scheduler job: {self._metadata.cloud_scheduler_job_name}\")\n\n        # Example: Different logic for first attempt vs retries\n        if self._metadata.first_attempt: # (5)\n            print(\"First attempt: trying the primary API endpoint.\")\n            # make_api_call(api_call_details, endpoint_type=\"primary\")\n        else:\n            print(\"Retry attempt: trying a fallback API endpoint or with reduced payload.\")\n            # make_api_call(api_call_details, endpoint_type=\"fallback\")\n\n        # Your main task logic here\n        # ...\n</code></pre> <ol> <li><code>attempt_number</code> reflects how many times Cloud Tasks has tried to dispatch this task.</li> <li><code>execution_number</code> reflects non-5XX responses.</li> <li>Check if the task has failed before.</li> <li>Check if the task was triggered by Cloud Scheduler.</li> <li>Implement different logic based on whether it's the first attempt or a retry.</li> </ol>"},{"location":"on_demand_tasks/#low-level-control","title":"Low-Level Control","text":"<p>For the most granular control over task enqueuing, you can use the <code>push()</code> class method directly. <code>asap()</code> and <code>later()</code> are convenient wrappers around <code>push()</code>. This allows you to specify custom headers, a dynamically generated task name (useful for more specific de-duplication than <code>only_once</code>), or override the queue dynamically.</p> <pre><code>import hashlib\n\nunique_part = hashlib.md5(f\"{user_id}-{item_id}\".encode()).hexdigest()  # (1)!\ndeterministic_task_name = f\"ProcessItemTask-{unique_part}\"\n\nSendWelcomeEmailTask.push(\n    task_kwargs={\"user_id\": 777, \"custom_message\": \"Pushed with full control!\"},\n    headers={\"X-Correlation-ID\": \"my-custom-trace-id\"}, # (2)!\n    delay_in_seconds=60, # (3)!\n    queue=\"another-dynamic-queue\", # (4)!\n    task_name=deterministic_task_name, # (5)!\n)\n</code></pre> <ol> <li>Generate a unique task name for de-duplication based on arguments</li> <li>Custom headers for this specific push.</li> <li>Delay by 1 minute.</li> <li>Can override queue here too.</li> <li>Provide a specific task name, e.g., for de-duplication.</li> </ol>"},{"location":"on_demand_tasks/#debugging-tasks","title":"Debugging Tasks","text":"<p>Django Cloud Tasks provides a couple of utility methods on your task classes for interacting with tasks already in a queue.</p> <p>If a task has failed in the cloud, or you want to re-run a specific execution locally with the exact same payload it had, you can use <code>debug()</code>.</p> <ul> <li>How it works: It fetches the task details (including its original payload) from Google Cloud Tasks using its <code>task_id</code> and then executes the <code>run()</code> method locally (synchronously) with that payload. It also populates <code>self._metadata</code> from the fetched task information.</li> </ul> <pre><code># from myapp.tasks import SendWelcomeEmailTask\n\ntask_id_from_gcp = \"1234567890abcdef\" # (1)!\nSendWelcomeEmailTask.debug(task_id=task_id_from_gcp)\n</code></pre> <ol> <li>You'd typically get the <code>task_id</code> from your Google Cloud Tasks Queue</li> </ol>"},{"location":"on_demand_tasks/#discarding-tasks","title":"Discarding Tasks","text":"<p>Once a bunch of tasks have been enqueued, it can be hard to keep track of them, specially when they start failing and cause a snowball effect of retries.</p> <p>For these use cases, you can remove tasks from a Google Cloud Tasks queue.</p> <p>Be careful</p> <p>This will delete tasks from a Google Cloud Tasks queue.</p> <p>Be very careful with this.</p>"},{"location":"on_demand_tasks/#discard-one-task","title":"Discard One Task","text":"<p>When you know exactly the problematic task, you can discard it by its Task ID.</p> <pre><code>task_id_from_gcp = \"1234567890abcdef\" # (1)!\nSendWelcomeEmailTask.discard(task_id=task_id_from_gcp)\n</code></pre> <ol> <li>You'd typically get the <code>task_id</code> from your Google Cloud Tasks Queue</li> </ol>"},{"location":"on_demand_tasks/#discard-all-tasks","title":"Discard All Tasks","text":"<p>If multiple tasks share the same queue, you can discard all tasks of a certain type.</p> <pre><code>SendWelcomeEmailTask.discard() # (1)!\n</code></pre> <ol> <li>This will list all tasks for <code>SendWelcomeEmailTask</code> in its default queue and delete them.</li> </ol>"},{"location":"on_demand_tasks/#discard-persistently-failing-tasks","title":"Discard Persistently Failing Tasks","text":"<p>You can discard tasks of a certain type that have met a minimum retry count.</p> <pre><code>SendWelcomeEmailTask.discard(min_retries=5) # (1)!\n</code></pre> <ol> <li>Deletes all <code>SendWelcomeEmailTask</code> instances from the queue that have been dispatched (retried) at least 5 times.</li> </ol>"},{"location":"on_demand_tasks/#handling-failed-tasks","title":"Handling Failed Tasks","text":"<p>Any exception raised by your task's <code>run()</code> method is considered a failure.</p> <p>This will inform Google Cloud Tasks to retry the task, according to the policy you've set.</p> <p>If you want to skip retrying a task, you can raise <code>DiscardTaskException</code> from within your task.</p> <pre><code>class MyTask(Task):\n    def run(self, *args, **kwargs):\n        # ...\n        raise DiscardTaskException(\"Task failed, skipping retries.\")\n</code></pre> <p>This covers the ins and outs of on-demand tasks. They form the foundation for many asynchronous operations in your Django application.</p>"},{"location":"pubsub/","title":"Publishing &amp; Subscribing","text":"<p>Django Cloud Tasks seamlessly integrates with Google Cloud Pub/Sub, enabling you to build powerful event-driven architectures.</p> <p>You can publish messages to Pub/Sub topics when something interesting happens in your application, and define subscriber tasks that react to these messages asynchronously.</p>"},{"location":"pubsub/#publishing","title":"Publishing","text":"<p>Messages are published to specific \"topics.\" You can think of a topic as a named channel for a certain category of events (e.g., \"user-signups\", \"order-updates\").</p> <p>There are two main base classes for creating publishers:</p> <ol> <li><code>PublisherTask</code>: For publishing general-purpose dictionary-based messages.</li> <li><code>ModelPublisherTask</code>: A specialized helper for easily publishing messages related to Django model instance events (e.g., when a model is created, updated, or deleted).</li> </ol>"},{"location":"pubsub/#basic-publisher","title":"Basic Publisher","text":"<p>Inherit from <code>PublisherTask</code> to define a generic message publisher. The primary method to override is <code>topic_name()</code>.</p> <p>Example: Publishing User Action Events</p> <p>Let's say we want to publish an event whenever a critical user action occurs, like a password change or profile update.</p> publishers.py<pre><code>from django_cloud_tasks.tasks import PublisherTask\n\nclass UserActionEventPublisher(PublisherTask):\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"user-actions\" # (1)!\n</code></pre> <ol> <li>The base name for the Pub/Sub topic. The final topic name in GCP might be prefixed (e.g., <code>my-app--user-actions</code>).</li> </ol> <p>Then, you can use it in any part of your codebase (e.g., in views or signals):</p> views.py<pre><code>from django.utils import timezone\nfrom .publishers import UserActionEventPublisher # Assuming this file is publishers.py\n\ndef my_view(request):\n    user = request.user\n    event_payload = {\n        \"user_id\": user.id,\n        \"action_type\": \"password_changed\",\n        # \"ip_address\": get_client_ip(request), # A helper function to get IP\n        \"timestamp\": timezone.now().isoformat()\n    }\n    UserActionEventPublisher.asap(\n        message=event_payload,\n        attributes={\"priority\": \"high\"},\n    )\n    # ... rest of view logic ...\n</code></pre> <p>Publishing Modes</p> <p>There are two main modes for publishing messages:</p> <ul> <li>Asynchronous Publishing (<code>asap</code>): The message is published asynchronously via Google Cloud Tasks. This is the recommended approach for most use cases.</li> <li>Synchronous Publishing (<code>sync</code>): The message is published synchronously in the current process. This is not recommended for most use cases, but can be useful for certain scenarios.</li> </ul>"},{"location":"pubsub/#model-publisher","title":"Model Publisher","text":"<p>Inherit from <code>ModelPublisherTask</code> to define a message publisher that is specifically tied to a Django model instance.</p> <p>Useful for Model Instances</p> <p>This class is incredibly useful when the event you want to publish is directly tied to a Django model instance (e.g. notifying that a model has been created, updated, or deleted).</p> <p>Example: Publishing Order Creation Events</p> publishers.py<pre><code>from django_cloud_tasks.tasks import ModelPublisherTask\nfrom .models import Order # Assuming Order model is in models.py\n\nclass OrderCreatedEvent(ModelPublisherTask):\n    @classmethod\n    def build_message_content(cls, obj: models.Model, **kwargs) -&gt; dict:\n        order = obj # Type hint as Order if needed: order: Order = obj\n        return {\n            \"order_id\": str(order.order_id),\n            \"user_id\": order.user_id,\n            \"total_amount\": float(order.total_amount), # (1)!\n            \"status\": order.status,\n            \"created_at_iso\": order.created_at.isoformat(),\n            \"campaign_source\": kwargs.get(\"campaign_source\") # (2)!\n        }\n\n    @classmethod\n    def build_message_attributes(cls, obj: models.Model, **kwargs) -&gt; dict[str, str]:\n        order = obj # Type hint as Order if needed\n        return {\n            \"event_type\": \"order_created\",\n            \"customer_segment\": \"retail\",\n            \"region\": kwargs.get(\"region\", \"unknown\")\n        }\n</code></pre> <ol> <li>Pub/Sub message content should ideally use basic JSON-serializable types.</li> <li>Extra keyword arguments passed to <code>asap()</code>, <code>sync()</code>, or <code>sync_on_commit()</code> are available in <code>build_message_content</code> and <code>build_message_attributes</code>.</li> <li><code>sync_on_commit</code> ensures the message is published only if the surrounding database transaction commits successfully.</li> </ol> <p>Then, you can use it in any part of your codebase (e.g., in signals):</p> signals.py<pre><code>from django.db import transaction\nfrom .publishers import OrderCreatedEvent\nfrom .models import Order\n\ndef order_created_handler(sender, instance, created, **kwargs):\n    if created:\n        OrderCreatedEvent.asap(\n            obj=instance,\n            campaign_source=\"spring_sale\",\n            region=\"emea\"\n        )\n    # ... rest of signal logic ...\n</code></pre> <p>Key methods for <code>ModelPublisherTask</code>:</p> <ul> <li><code>build_message_content(cls, obj: Model, **kwargs) -&gt; dict</code> (Required): You implement this to transform your model instance (<code>obj</code>) and any extra <code>kwargs</code> into the main JSON payload of the Pub/Sub message.</li> <li><code>build_message_attributes(cls, obj: Model, **kwargs) -&gt; dict[str, str]</code> (Required): You implement this to create a dictionary of string-to-string attributes for the Pub/Sub message. Attributes are useful for filtering messages on the subscriber side without needing to parse the full JSON payload.</li> <li><code>sync_on_commit(obj: Model, **kwargs)</code>: A very handy method that delays the actual publishing until the current database transaction is successfully committed. This prevents sending messages for data that might be rolled back.</li> </ul>"},{"location":"pubsub/#topic-naming-convention","title":"Topic Naming Convention","text":"<ul> <li>Default <code>topic_name()</code> for <code>PublisherTask</code>: Uses the class name (e.g., <code>UserActionEventPublisher</code> becomes topic base name <code>UserActionEventPublisher</code>).</li> <li>Default <code>topic_name()</code> for <code>ModelPublisherTask</code>: Uses <code>app_label-model_name</code> (e.g., if <code>Order</code> is in <code>sales</code> app, it becomes <code>sales-order</code>).</li> <li>Global Prefixing: If <code>DJANGO_CLOUD_TASKS_APP_NAME</code> is set in your Django settings (e.g., to <code>\"my-ecom-service\"</code>), this name, along with the <code>DJANGO_CLOUD_TASKS_DELIMITER</code> (default <code>\"--\"</code>), will be prepended to the base topic name. So, <code>UserActionEventPublisher</code> could become <code>my-ecom-service--UserActionEventPublisher</code> in GCP.</li> <li>This prefixing helps organize topics in GCP, especially if multiple services share a project.</li> </ul>"},{"location":"pubsub/#subscribing","title":"Subscribing","text":"<p>To process messages published to a topic, you define a <code>SubscriberTask</code>.</p> <p>This task will be triggered via an HTTP push request from Google Cloud Pub/Sub to a dedicated endpoint in your Django application when a new message arrives on the subscribed topic.</p> <p>Example: Processing User Action Events and Order Notifications</p> subscribers.py<pre><code>from django_cloud_tasks.tasks import SubscriberTask\n\n\nclass UserActionAuditor(SubscriberTask):\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"user-actions\" # (1)!\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None):\n        print(f\"Auditing user action: {content.get('action_type')} for user {content.get('user_id')}\")\n        print(f\"  Attributes: {attributes}\")\n        # ... rest of subscriber logic ...\n        return {\"status\": \"action_audited\", \"user_id\": content.get('user_id')}\n\n\nclass OrderNotificationHandler(SubscriberTask):\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"sales-order\" # (2)!\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None):\n        print(f\"New order received for processing: {content.get('order_id')}\")\n        print(f\"  Event Type (from attribute): {attributes.get('event_type')}\")\n        # ... rest of subscriber logic ...\n        return {\"status\": \"order_processed\", \"order_id\": content.get('order_id')}\n</code></pre> <ol> <li>The base topic name this subscriber listens to. Must match the <code>topic_name</code> of <code>UserActionEventPublisher</code>.</li> <li>The base topic name for order-related events. Must match the <code>topic_name</code> used by <code>OrderCreatedEvent</code>.</li> </ol> <p>Key elements for <code>SubscriberTask</code>:</p> <ul> <li><code>topic_name(cls) -&gt; str</code> (Required): Specifies which Pub/Sub topic this task subscribes to. This name needs to match the base name of the publisher's topic (before any global <code>APP_NAME</code> prefixing).</li> <li><code>run(content: dict, attributes: dict[str, str] | None = None)</code>: Your core logic to handle the incoming message. <code>content</code> is the deserialized JSON payload, and <code>attributes</code> are the string key-value pairs sent with the Pub/Sub message.</li> </ul>"},{"location":"pubsub/#subscription-naming-convention","title":"Subscription Naming Convention","text":"<ul> <li>Default <code>subscription_name()</code>: Similar to topics, the subscription name is derived from <code>DJANGO_CLOUD_TASKS_APP_NAME</code> (if set), the <code>DJANGO_CLOUD_TASKS_DELIMITER</code>, and the <code>SubscriberTask</code> class name (e.g., <code>my-ecom-service--UserActionAuditor</code>).</li> <li>This name is used for the actual Pub/Sub Subscription resource created in GCP.</li> </ul>"},{"location":"pubsub/#setting-up-and-deploying-subscriptions","title":"Setting Up and Deploying Subscriptions","text":"<p>Defining the <code>SubscriberTask</code> class in Python doesn't automatically create the subscription in Google Cloud Pub/Sub. You need to run a management command to assure that the subcriptions defined in your codebase are properly reflected in GCP.</p> <p>Subscriptions will be created, updated, or deleted as needed.</p> <pre><code>python manage.py initialize_subscribers\n</code></pre> <p>When to run <code>initialize_subscribers</code>?</p> <p>Run this as part of your deployment process, especially when you add new <code>SubscriberTask</code>s or change their subscription configurations (like <code>topic_name</code>, <code>filter</code>, retry policies, etc.).</p>"},{"location":"pubsub/#how-it-works-under-the-hood","title":"How It Works Under the Hood","text":"<p>Understanding the flow of messages from publisher to subscriber can be helpful for debugging and advanced configurations.</p>"},{"location":"pubsub/#synchronous-publishing-flow","title":"Synchronous Publishing Flow","text":"<p>In this mode, the call to publish the message to Google Cloud Pub/Sub happens directly in the process that initiated it.</p> <p>You can perform this operation by calling <code>YourPublisher.sync(message, attributes)</code>.</p> <pre><code>sequenceDiagram\n    participant App as Django App\n    participant DCT as django-cloud-tasks\n    participant GPS as Google Cloud Pub/Sub\n\n    App-&gt;&gt;DCT: User code calls YourPublisher.sync(message, attributes)\n    DCT-&gt;&gt;GPS: Publishes message to Pub/Sub topic\n    GPS--&gt;&gt;DCT: Acknowledges publish\n    DCT--&gt;&gt;App: Returns result</code></pre> <p>Steps for Synchronous Publishing:</p> <ol> <li>Initiation: Your application code calls <code>YourPublisher.sync(message, attributes)</code>.</li> <li>Direct Call: The <code>django-cloud-tasks</code> library directly invokes the Google Cloud Pub/Sub API to publish the provided message and attributes.</li> <li>Acknowledgment: Google Cloud Pub/Sub acknowledges the receipt of the message.</li> <li>Return: The <code>sync()</code> method returns. This operation is blocking.</li> </ol>"},{"location":"pubsub/#asynchronous-publishing-flow","title":"Asynchronous Publishing Flow","text":"<p>This is the recommended approach for scenarios like web requests where you don't want to block the main process.</p> <p>Publishing is offloaded to a background task via Google Cloud Tasks.</p> <p>You can perform this operation by calling <code>YourPublisher.asap(message, attributes)</code>.</p> <pre><code>sequenceDiagram\n    participant App as Django App\n    participant DCT as django-cloud-tasks\n    participant GCT as Google Cloud Tasks\n    participant GPS as Google Cloud Pub/Sub\n\n    App-&gt;&gt;DCT: User calls YourPublisher.asap(msg, attrs) (Request Context)\n    DCT-&gt;&gt;GCT: Enqueues task (target: DjangoApp's task handler endpoint)\n    GCT--&gt;&gt;DCT: Acknowledges task creation\n    DCT--&gt;&gt;App: Returns immediately (task enqueued)\n\n    GCT-&gt;&gt;DCT: Invokes Task Handler endpoint (Task Handler Context)\n    DCT-&gt;&gt;GPS: Publishes message to Pub/Sub topic\n    GPS--&gt;&gt;DCT: Acknowledges publish\n    DCT--&gt;&gt;GCT: Task Acknowledged (e.g., HTTP 2xx response)</code></pre> <p>Steps for Asynchronous Publishing:</p> <ol> <li>Initiation (Django App - Request Context): Your application code (e.g., in a Django view) calls <code>YourPublisher.asap(message, attributes)</code> using the <code>django-cloud-tasks</code> library.</li> <li>Task Creation (django-cloud-tasks Library): The library code within your <code>DjangoApp</code> constructs a request to the <code>Google Cloud Tasks</code> service. This request defines a new task, specifying the payload (your message and attributes) and the target (an HTTP endpoint within your own <code>DjangoApp</code> designated for processing these publish tasks).</li> <li>Enqueueing (Google Cloud Tasks Service): The <code>Google Cloud Tasks</code> service receives the request, creates the task, and stores it in a queue. It then acknowledges task creation back to the <code>django-cloud-tasks</code> library.</li> <li>Immediate Return (Django App - Request Context): The <code>asap()</code> method in your application code returns quickly to the caller (e.g., your Django view), as its primary job (enqueueing the task) is complete. The actual publishing happens in the background.</li> <li>Task Invocation (Google Cloud Tasks Service to Django App - Task Handler Context): At a later time, the <code>Google Cloud Tasks</code> service dequeues the task and invokes the target handler endpoint in your <code>DjangoApp</code>. This is an HTTP POST request to a specific URL in your application (e.g., handled by <code>django_cloud_tasks.views.ProcessCloudTaskView</code>).</li> <li>Message Publishing (Django App - Task Handler Context using django-cloud-tasks Library): The task handler code within your <code>DjangoApp</code> (specifically, the <code>django-cloud-tasks</code> view that processes the task) extracts the message and attributes from the task payload. It then re-uses the <code>django-cloud-tasks</code> library's internal publishing logic to send the message to the <code>Google Cloud Pub/Sub</code> service.</li> <li>Pub/Sub Acknowledgment (Google Cloud Pub/Sub to django-cloud-tasks Library): <code>Google Cloud Pub/Sub</code> receives the message, stores it, and acknowledges its receipt back to the <code>django-cloud-tasks</code> publishing logic running within your task handler.</li> <li>Task Completion (Django App - Task Handler Context to Google Cloud Tasks Service): After successfully publishing to Pub/Sub, your task handler (via the <code>django-cloud-tasks</code> library) returns an HTTP 2xx success response to the <code>Google Cloud Tasks</code> service. This acknowledges that the task has been completed successfully, and <code>Google Cloud Tasks</code> will not attempt to retry it.</li> </ol>"},{"location":"pubsub/#subscription-flow","title":"Subscription Flow","text":"<p>Once a message is in Pub/Sub, the delivery to subscribers happens as follows (assuming a push subscription, which is the default for <code>django-cloud-tasks</code>):</p> <pre><code>sequenceDiagram\n    participant GPS as Google Cloud Pub/Sub\n    participant DCT as django-cloud-tasks\n    participant App as Django App\n\n    GPS-&gt;&gt;DCT: HTTP POST to Push Endpoint\n    DCT-&gt;&gt;DCT: Validates request (e.g., OIDC token)\n    DCT-&gt;&gt;App: Finds &amp; calls YourSubscriberTask.run\n    App-&gt;&gt;App: Executes user's task logic\n    App--&gt;&gt;DCT: Returns result/status\n    DCT--&gt;&gt;GPS: HTTP 2xx Acknowledgment (if successful)</code></pre> <p>Steps for Subscription Flow:</p> <ol> <li>Message Delivery: When a message is published to a topic, Google Cloud Pub/Sub identifies all subscriptions for that topic. For push subscriptions, Pub/Sub sends an HTTP POST request.</li> <li>Push Endpoint: This request is sent to a unique URL generated by <code>django-cloud-tasks</code> for each <code>SubscriberTask</code> (e.g., <code>/_tasks/pubsub/MyApp--MySubscriberTaskName/</code>). This endpoint is handled by <code>django_cloud_tasks.views.ProcessPubSubPushView</code>.</li> <li>Request Handling by <code>django-cloud-tasks</code>:<ul> <li>Receives the incoming HTTP request.</li> <li>Validates the request, typically by checking an OIDC token attached by Google Pub/Sub to ensure authenticity (i.e., that the request genuinely came from Pub/Sub for that specific subscription).</li> <li>Extracts the message content (deserialized from JSON by default) and attributes.</li> </ul> </li> <li>User Task Execution:<ul> <li>The library identifies the correct <code>SubscriberTask</code> class based on the URL.</li> <li>It instantiates the task and calls its <code>run(content, attributes)</code> method, passing the deserialized message.</li> </ul> </li> <li>Acknowledgment to Pub/Sub:<ul> <li>If your <code>run()</code> method completes successfully (i.e., doesn't raise an unhandled exception), <code>django-cloud-tasks</code> returns an HTTP 2xx status code (e.g., 200 OK or 204 No Content) back to Google Cloud Pub/Sub.</li> <li>This 2xx response acknowledges that the message has been successfully processed. Pub/Sub will then not attempt to redeliver it.</li> <li>If your <code>run()</code> method raises an exception, or if the endpoint returns a non-2xx status (e.g., 500), Pub/Sub will consider the message delivery failed and will attempt to redeliver it according to the subscription's configured retry policy.</li> </ul> </li> </ol> <p>This overall flow leverages Google Cloud's infrastructure for reliable, at-least-once message delivery.</p>"},{"location":"pubsub/#advanced-pubsub-configuration","title":"Advanced Pub/Sub Configuration","text":""},{"location":"pubsub/#custom-topic-names","title":"Custom Topic Names","text":"<p>For both <code>PublisherTask</code> and <code>ModelPublisherTask</code>, you can override <code>topic_name(cls, ...)</code> for more control.</p> publishers.py<pre><code>from django.db import models # Assuming you're using models with ModelPublisherTask\nfrom django_cloud_tasks.tasks import PublisherTask, ModelPublisherTask\n\nclass LegacySystemEventPublisher(PublisherTask):\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"legacy-integration-bus\" # (1)!\n\n# For ModelPublisherTask, topic_name can also use the object\nclass ProductUpdateToSpecificChannel(ModelPublisherTask): # (2)!\n    @classmethod\n    def topic_name(cls, obj: models.Model, **kwargs) -&gt; str: # (3)!\n        product = obj # Type hint as Product if needed\n        if product.category == \"electronics\":\n            return \"product-updates-electronics\"\n        return \"product-updates-general\"\n\n    # Remember to implement build_message_content and build_message_attributes\n    @classmethod\n    def build_message_content(cls, obj: models.Model, **kwargs) -&gt; dict:\n        # Replace with actual implementation\n        return {\"product_id\": obj.pk, \"name\": getattr(obj, 'name', '')}\n\n    @classmethod\n    def build_message_attributes(cls, obj: models.Model, **kwargs) -&gt; dict[str, str]:\n        # Replace with actual implementation\n        return {\"category\": getattr(obj, 'category', 'unknown')}\n</code></pre> <ol> <li>Overrides the default naming (based on class name) to a fixed, custom topic name.</li> <li>This example demonstrates dynamically choosing a topic based on the model's data.</li> <li>When <code>ModelPublisherTask.topic_name</code> accepts an <code>obj</code> argument, it can tailor the topic per instance.</li> </ol> <p>Remember that if <code>DJANGO_CLOUD_TASKS_APP_NAME</code> is set, it will still be prefixed unless your override includes it or is absolute.</p>"},{"location":"pubsub/#custom-subscription-name","title":"Custom Subscription Name","text":"<p>While default naming is usually fine, you can override <code>subscription_name()</code> if needed, similar to <code>schedule_name</code> for periodic tasks.</p>"},{"location":"pubsub/#custom-subscription-url","title":"Custom Subscription URL","text":"<p>This is rarely needed, as the default URL points to the correct handler in <code>django-cloud-tasks</code>. Overriding this means you're pointing Pub/Sub to a custom endpoint you've built.</p>"},{"location":"pubsub/#oidc-authentication","title":"OIDC Authentication","text":"<ul> <li>Class attribute <code>_use_oidc_auth: bool = True</code>.</li> <li>Controls if the Pub/Sub push subscription expects Google to send an OIDC token for authentication. Generally, keep this <code>True</code> if your Django app runs on a service like Cloud Run that can validate these tokens.</li> </ul>"},{"location":"pubsub/#subscription-retry-policy","title":"Subscription Retry Policy","text":"<p>These settings on your <code>SubscriberTask</code> class map to the Pub/Sub subscription's message delivery retry configuration. They define how Pub/Sub handles messages if your endpoint doesn't acknowledge them (e.g., returns an error or times out).</p> <ul> <li><code>max_retries: int | None = UNSET</code>: Maximum delivery attempts before sending to a dead-letter topic (if configured). Defaults to global <code>DJANGO_CLOUD_TASKS_SUBSCRIBER_MAX_RETRIES</code> or GCP default.</li> <li><code>min_backoff: int | None = UNSET</code>: Minimum delay (in seconds) Pub/Sub waits before redelivering an unacknowledged message. Defaults to global <code>DJANGO_CLOUD_TASKS_SUBSCRIBER_MIN_BACKOFF</code> or GCP default (typically 10s).</li> <li><code>max_backoff: int | None = UNSET</code>: Maximum delay (in seconds) for redelivery. Defaults to global <code>DJANGO_CLOUD_TASKS_SUBSCRIBER_MAX_BACKOFF</code> or GCP default (typically 600s).</li> </ul> subscribers.py<pre><code>from django_cloud_tasks.tasks import SubscriberTask\nfrom django_cloud_tasks.constants import UNSET\n\nclass TimeSensitiveAlertSubscriber(SubscriberTask):\n    _use_oidc_auth = True # Ensure OIDC token is expected\n    max_retries = 5         # (1)!\n    min_backoff = 20        # (2)!\n    max_backoff = 120       # (3)!\n\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"critical-alerts\"\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None):\n        # Process time-sensitive alert\n        print(f\"Processing alert: {content}\")\n        # ...\n        return {\"status\": \"alert_processed\"}\n\n# Example of using a dead-letter topic\nclass ImportantEventSubscriber(SubscriberTask):\n    dead_letter_topic_name = \"failed-important-events\" # (4)!\n    # dead_letter_subscription_name = \"my-app--custom-dlt-sub-for-important-events\" # (5)!\n    max_retries = 3 # (6)!\n\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"important-events\"\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None):\n        # Process important event\n        if content.get(\"value\") == \"problem\": # Simulate a processing failure\n             raise ValueError(\"Simulated processing error for important event\")\n        print(f\"Processing event: {content}\")\n        return {\"status\": \"event_processed\"}\n</code></pre> <ol> <li>Attempt message delivery up to 5 times.</li> <li>Wait at least 20 seconds before the first retry.</li> <li>Cap the maximum delay between retries to 120 seconds.</li> <li>If message processing fails after <code>max_retries</code> (3 in this case), it will be sent to the Pub/Sub topic named <code>failed-important-events</code> (prefixed by <code>DJANGO_CLOUD_TASKS_APP_NAME</code> if set).</li> <li>Optionally, specify a custom name for the dead-letter subscription itself. If not set, a default name will be generated.</li> <li>Try processing up to 3 times before the message is eligible for the dead-letter topic.</li> </ol>"},{"location":"pubsub/#dead-letter-topics","title":"Dead Letter Topics","text":"<p>If a message consistently fails processing after configured retries, Pub/Sub can forward it to a Dead Letter Topic (DLT). This is crucial for ensuring that problematic messages don't get stuck in an infinite retry loop and can be investigated later.</p> <ul> <li><code>dead_letter_topic_name: str | None = None</code>: The base name of the Pub/Sub topic to use as a DLT. If set, <code>django-cloud-tasks</code> will configure the main subscription to send messages here after <code>max_retries</code> have been exhausted. The actual DLT name in GCP will be prefixed by <code>DJANGO_CLOUD_TASKS_APP_NAME</code> if configured.</li> <li><code>dead_letter_subscription_name: str | None = None</code>: Optionally, specify a custom name for the subscription that <code>django-cloud-tasks</code> creates for the dead-letter topic. If not provided, a default name is generated. This subscription is just a way to inspect messages in the DLT; you might also have a separate <code>SubscriberTask</code> listening to this DLT for automated processing or alerting.</li> </ul> <p>The <code>initialize_subscribers</code> command will attempt to create the dead-letter topic if it doesn't exist and grant the necessary permissions for the Pub/Sub service account to publish to it.</p>"},{"location":"pubsub/#message-filtering","title":"Message Filtering","text":"<p>Pub/Sub allows subscriptions to specify a filter, so the subscription only receives messages whose attributes match the filter. This can reduce the number of messages your subscriber task needs to process and can be more efficient than filtering in your task's <code>run</code> method.</p> <ul> <li><code>subscription_filter: str | None = None</code>: A class attribute. Set this to a filter string according to the Pub/Sub filter syntax.</li> </ul> subscribers.py<pre><code>from django_cloud_tasks.tasks import SubscriberTask\n\nclass FilteredEventSubscriber(SubscriberTask):\n    # Example: attributes.eventType = \"user_signup\" OR attributes.priority = 'high'\n    subscription_filter = 'attributes.event_type = \"user_signup\" OR attributes.event_type = \"user_delete\"'  # (1)!\n\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"generic-user-events\"\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None):\n        event_type = attributes.get(\"event_type\")\n        print(f\"Processing filtered event of type '{event_type}': {content}\")\n        # ... logic for user_signup or user_delete events\n        return {\"status\": f\"{event_type}_processed\"}\n</code></pre> <ol> <li>This filter string tells Pub/Sub to only deliver messages that have an <code>event_type</code> attribute of either <code>\"user_signup\"</code> or <code>\"user_delete\"</code>. The filter is applied by GCP Pub/Sub before delivering the message.</li> </ol>"},{"location":"pubsub/#custom-message-parser","title":"Custom Message Parser","text":"<p>By default, <code>SubscriberTask</code> expects the Pub/Sub message data to be a JSON-encoded string (UTF-8). If your messages are published in a different format (e.g., plain text, Avro, Protobuf), you can provide a custom static method to parse the raw message body.</p> <ul> <li><code>message_parser(data: bytes, attributes: dict[str, str] | None = None) -&gt; TypedMessage</code>: A <code>staticmethod</code> on your <code>SubscriberTask</code> class.<ul> <li>It receives the raw message <code>data</code> as <code>bytes</code> and the message <code>attributes</code>.</li> <li>It should return an instance of <code>django_cloud_tasks.typed_message_sender.TypedMessage</code>. The <code>content</code> field of this <code>TypedMessage</code> can be any Python object (e.g., a Pydantic model, a dictionary, a custom class instance).</li> <li>The <code>run</code> method of your task will then receive this parsed object as its <code>content</code> argument.</li> </ul> </li> </ul> subscribers.py<pre><code>import json # Or your custom deserialization library\nfrom django_cloud_tasks.tasks import SubscriberTask\nfrom django_cloud_tasks.typed_message_sender import TypedMessage # (1)!\n\n# Assume this Pydantic model is defined elsewhere, e.g., in schemas.py\n# from pydantic import BaseModel, Field\n# from typing import Literal\n# class UserActivity(BaseModel):\n#     user_id: int\n#     activity_type: Literal[\"login\", \"logout\", \"post_comment\"]\n#     timestamp: str # ISO format string\n\nclass PydanticMessageSubscriber(SubscriberTask):\n    @classmethod\n    def topic_name(cls) -&gt; str:\n        return \"user-activity-stream\"\n\n    @staticmethod\n    def message_parser(data: bytes, attributes: dict[str, str] | None = None) -&gt; TypedMessage: # (2)!\n        # from .schemas import UserActivity # Assuming UserActivity is in schemas.py\n        # For this example, we'll use a simple dict instead of a Pydantic model\n        # to avoid adding a Pydantic dependency just for this example.\n        # In a real scenario, you would parse into your Pydantic model here:\n        # parsed_content = UserActivity.model_validate_json(data.decode(\"utf-8\"))\n        # return TypedMessage(content=parsed_content, attributes=attributes)\n\n        # Simple dictionary parsing for example purposes\n        content = json.loads(data.decode(\"utf-8\")) # (3)!\n        return TypedMessage(content=content, attributes=attributes) # (4)!\n\n    def run(self, content: dict, attributes: dict[str, str] | None = None): # (5)!\n        # If using Pydantic: user_activity: UserActivity = content\n        # Now 'content' is whatever your message_parser returned (e.g., a UserActivity instance or dict here)\n        # print(f\"Processing Pydantic model: User {user_activity.user_id} did {user_activity.activity_type}\")\n        print(f\"Processing parsed message: {content}\")\n        return {\"status\": \"parsed_message_processed\"}\n</code></pre> <ol> <li><code>TypedMessage</code> is a simple data structure (<code>NamedTuple</code>) provided by the library to hold the parsed <code>content</code> and original <code>attributes</code>.</li> <li>Define <code>message_parser</code> as a <code>staticmethod</code> that takes <code>bytes</code> and returns <code>TypedMessage</code>.</li> <li>Decode the <code>bytes</code> (e.g., from UTF-8) and parse it (e.g., using <code>json.loads</code> or a Pydantic model's <code>model_validate_json</code>).</li> <li>Return a <code>TypedMessage</code> instance. The <code>content</code> attribute can be any Python object.</li> <li>The <code>run</code> method's <code>content</code> argument will now be the object that was in <code>TypedMessage.content</code> (e.g., a dictionary in this example, or an instance of <code>UserActivity</code> if you were using Pydantic).</li> </ol> <p>This provides a powerful way to integrate with diverse message formats and leverage strong typing within your subscriber logic.</p> <p>This event-driven model using Pub/Sub provides a robust and scalable way to build decoupled applications where services can communicate and react to events without direct dependencies. </p>"},{"location":"scheduled_tasks/","title":"Scheduled Tasks (Cron Jobs) :fontawesome-solid-calendar-alt:","text":"<p>Scheduled tasks, often known as cron jobs, are tasks that run automatically at predefined times or intervals. <code>django-cloud-tasks</code> leverages Google Cloud Scheduler to manage and execute these tasks.</p>"},{"location":"scheduled_tasks/#defining-a-scheduled-task","title":"Defining a Scheduled Task","text":"<p>To define a scheduled task, you create a class that inherits from <code>django_cloud_tasks.tasks.PeriodicTask</code> and implement the <code>run()</code> method. Additionally, you must define the schedule using the <code>run_every</code> attribute.</p> <p>Example: Daily Digest and Hourly Cleanup</p> tasks.py<pre><code>from django_cloud_tasks.tasks import PeriodicTask\nfrom django.utils import timezone\n\nclass GenerateDailyUserActivityDigest(PeriodicTask):\n    run_every = \"0 0 * * 1-5\" # (1)!\n\n    def run(self, **kwargs):\n        print(f\"Generating daily user activity digest for {timezone.now().date()}...\")\n        # TODO: Implement the logic to generate the daily user activity digest\n        return {\"status\": \"digest_generated\", \"date\": str(timezone.now().date())}\n\n\nclass HourlyTemporaryFileCleanup(PeriodicTask):\n    run_every = \"@hourly\"  # (2)!\n\n    def run(self, older_than_hours: int = 2, **kwargs): # (3)!\n        print(f\"Cleaning up temporary files older than {older_than_hours} hours...\")\n        # TODO: Implement the logic to clean up temporary files\n        return {\"status\": \"cleanup_done\", \"older_than_hours\": older_than_hours}\n</code></pre> <ol> <li>Cron expression: \"At 00:00 (UTC by default) on every day-of-week from Monday through Friday.\"</li> <li>Cloud Scheduler shorthand for \"0 * * * *\" (at the beginning of every hour).</li> <li>The <code>run</code> method can accept parameters. If a payload is configured for the Cloud Scheduler job (see Custom Payload section), those key-values will be passed here. Otherwise, only default parameter values are used.</li> </ol> <p>Key Attributes for <code>PeriodicTask</code>:</p> <ul> <li><code>run_every: str</code> (Required): Defines the schedule using the standard cron format. Cloud Scheduler also supports shorthands like <code>@daily</code>, <code>@hourly</code>, <code>@weekly</code>, <code>@monthly</code>, <code>@yearly</code>.</li> <li><code>run(**kwargs)</code>: The method containing your task's logic. It's the same as for on-demand tasks. Any JSON payload you define in Cloud Scheduler (or through customization hooks) will be passed as <code>kwargs</code>.</li> </ul>"},{"location":"scheduled_tasks/#deploying-scheduled-tasks","title":"Deploying Scheduled Tasks","text":"<p>Defining the <code>PeriodicTask</code> class in your Python code doesn't automatically create or update the job in Google Cloud Scheduler. You need to run a management command:</p> <pre><code>python manage.py schedule_tasks\n</code></pre> <p>What this command does:</p> <ol> <li>Scans your project for all classes that inherit from <code>PeriodicTask</code>.</li> <li>For each task found, it compares its definition (schedule, payload, OIDC settings, etc.) with what's currently configured in Google Cloud Scheduler for a job with the same name (derived from the task class).</li> <li>It then creates, updates, or deletes jobs in Google Cloud Scheduler as needed to match your Python definitions.<ul> <li><code>[+] Job created: your_app.tasks.NightlyCleanupTask</code></li> <li><code>[~] Job updated: your_app.tasks.HourlyReportTask</code> (if, for example, <code>run_every</code> changed)</li> <li><code>[-] Job deleted: your_app.tasks.OldRemovedTask</code> (if a task class was removed from code)</li> </ul> </li> </ol> <p>When to run <code>schedule_tasks</code>?</p> <p>Run this command as part of your deployment process. Any time you add a new <code>PeriodicTask</code>, remove one, or change its <code>run_every</code> schedule or other schedule-related attributes, you should run this command to synchronize your GCP environment.</p> <p>Idempotency</p> <p>The <code>schedule_tasks</code> command is idempotent. You can run it multiple times, and it will only make changes if there are differences between your code and the state in Google Cloud Scheduler.</p>"},{"location":"scheduled_tasks/#customizing-scheduled-task-behavior-fontawesome-solid-sliders-h","title":"Customizing Scheduled Task Behavior :fontawesome-solid-sliders-h:","text":"<p><code>PeriodicTask</code> offers several attributes and methods to customize how it's scheduled and executed.</p>"},{"location":"scheduled_tasks/#custom-job-name-schedule_name","title":"Custom Job Name (<code>schedule_name</code>)","text":"<p>By default, the Google Cloud Scheduler job name is derived from the task's class path (e.g., <code>your_app.tasks.NightlyCleanupTask</code>, potentially prefixed by <code>DJANGO_CLOUD_TASKS_APP_NAME</code>). You can provide a custom name:</p> <p>tasks.py<pre><code>class CustomNamedJob(PeriodicTask):\n    run_every = \"0 0 1 * *\" # First day of every month\n\n    @classmethod\n    def schedule_name(cls) -&gt; str: # (1)!\n        return \"monthly-financial-summary\"\n\n    def run(self):\n        # ... generate financial summary ...\n        return {\"summary\": \"done\"}\n</code></pre> 1.  The job in GCP will be named <code>monthly-financial-summary</code> (or <code>my-app--monthly-financial-summary</code>).</p>"},{"location":"scheduled_tasks/#custom-headers-for-scheduler-schedule_headers","title":"Custom Headers for Scheduler (<code>schedule_headers</code>)","text":"<p>If the HTTP request made by Cloud Scheduler to your Django app needs specific headers (e.g., for an external gateway or specific tracing), you can define them:</p> <p>tasks.py<pre><code>class TaskWithCustomHeaders(PeriodicTask):\n    run_every = timedelta(minutes=30)\n\n    @classmethod\n    def schedule_headers(cls) -&gt; dict[str, str]: # (1)!\n        return {\n            \"X-Custom-Auth-Token\": \"some_secret_value\",\n            \"X-Source-System\": \"django-scheduler\"\n        }\n\n    def run(self):\n        # Headers will be available in self.request.META or self._metadata.headers\n        # if DJANGO_CLOUD_TASKS_PROPAGATE_HEADERS is True\n        return {\"status\": \"ok\"}\n</code></pre> 1.  These headers will be sent by Google Cloud Scheduler when it triggers your task.</p>"},{"location":"scheduled_tasks/#oidc-authentication-schedule_use_oidc","title":"OIDC Authentication (<code>schedule_use_oidc</code>)","text":"<p>By default (<code>schedule_use_oidc = True</code>), <code>django-cloud-tasks</code> configures Cloud Scheduler jobs to use OIDC authentication. Google Cloud Scheduler will send an OIDC token in the <code>Authorization</code> header, which your Django app (running on Cloud Run, GKE, or App Engine) can validate.</p> <p>If you are running your Django app in an environment that cannot validate these tokens, or if you have a different authentication mechanism (e.g., an API gateway in front), you might disable this:</p> <p>tasks.py<pre><code>class NoOidcTask(PeriodicTask):\n    run_every = \"every 2 hours\"\n    schedule_use_oidc = False # (1)!\n\n    def run(self):\n        # ... task logic ...\n        return {\"oidc_disabled\": True}\n</code></pre> 1.  The Cloud Scheduler job will be created without an OIDC token configuration. Your endpoint needs to be publicly accessible or use a different auth method.</p>"},{"location":"scheduled_tasks/#custom-retry-configuration-for-scheduler-schedule_retries","title":"Custom Retry Configuration for Scheduler (<code>schedule_retries</code>)","text":"<p>Google Cloud Scheduler has its own retry mechanism if the HTTP call to your task endpoint fails (e.g., returns a 5xx error or times out). You can customize these retry attempts:</p> <p>tasks.py<pre><code>class TaskWithCustomRetries(PeriodicTask):\n    run_every = \"0 * * * *\" # Every hour at minute 0\n\n    @classmethod\n    def schedule_retries(cls) -&gt; int | None: # (1)!\n        return 5  # Attempt up to 5 times if the initial call fails\n\n    # You can also specify min/max backoff and max duration for retries\n    # @classmethod\n    # def schedule_min_backoff(cls) -&gt; timedelta | None:\n    #     return timedelta(seconds=30)\n    # @classmethod\n    # def schedule_max_backoff(cls) -&gt; timedelta | None:\n    #     return timedelta(minutes=10)\n    # @classmethod\n    # def schedule_max_doublings(cls) -&gt; int | None: # How many times to double backoff\n    #     return 3\n\n    def run(self):\n        # ... task logic ...\n        return {\"status\": \"processed\"}\n</code></pre> 1.  Corresponds to <code>RetryConfig.retry_count</code> in Cloud Scheduler.</p>"},{"location":"scheduled_tasks/#custom-payload-schedule_body_payload","title":"Custom Payload (<code>schedule_body_payload</code>)","text":"<p>While <code>PeriodicTask</code> usually doesn't require a payload (as it's run on a schedule, not in response to specific data), you can send a JSON payload from Cloud Scheduler if needed. This payload will be passed as keyword arguments to your <code>run()</code> method.</p> <p>tasks.py<pre><code>class TaskWithPayload(PeriodicTask):\n    run_every = \"0 9 * * 1-5\"  # 9 AM on weekdays\n\n    @classmethod\n    def schedule_body_payload(cls) -&gt; dict | None: # (1)!\n        return {\n            \"report_type\": \"daily_sales\",\n            \"region\": \"emea\"\n        }\n\n    def run(self, report_type: str, region: str):\n        print(f\"Running scheduled task for report: {report_type} in region: {region}\")\n        # ... logic using report_type and region ...\n        return {\"processed_report\": report_type, \"region\": region}\n</code></pre> 1.  The <code>run</code> method will receive <code>report_type=\"daily_sales\"</code> and <code>region=\"emea\"</code>.</p>"},{"location":"scheduled_tasks/#other-schedule-attributes","title":"Other Schedule Attributes","text":"<p><code>PeriodicTask</code> allows further customization of the Cloud Scheduler job via class methods, corresponding to <code>Job</code> attributes in the GCP API:</p> <ul> <li><code>schedule_description() -&gt; str | None</code>: A human-readable description for the job.</li> <li><code>schedule_time_zone() -&gt; str | None</code>: Timezone for cron schedules (e.g., \"America/New_York\"). Default is UTC.</li> <li><code>schedule_attempt_deadline() -&gt; timedelta | None</code>: Time limit for Cloud Scheduler to attempt to deliver the PUSH request to your app. If the task handler takes longer than this, Scheduler might consider it a failure. Default is 3 minutes.</li> </ul>"},{"location":"scheduled_tasks/#how-it-works-under-the-hood-fontawesome-solid-cogs","title":"How It Works Under the Hood :fontawesome-solid-cogs:","text":"<p>When <code>PeriodicTask.schedule()</code> is invoked (typically by the <code>schedule_tasks</code> management command), it communicates with Google Cloud Scheduler to create or update a job. This job is configured to:</p> <ol> <li>Trigger based on the <code>run_every</code> cron schedule.</li> <li>Make an HTTP POST request to the URL generated by <code>YourTaskClass.url()</code> (this defaults to the standard task execution endpoint in <code>django_cloud_tasks.urls</code>).</li> <li>Include a JSON payload (by default, an empty dictionary <code>{}</code> unless <code>kwargs</code> were passed to <code>schedule</code> or the task sends a default payload).</li> <li>Use OIDC authentication and custom headers as configured.</li> </ol> <p>Essentially, Cloud Scheduler acts as a timed trigger that invokes your <code>PeriodicTask</code> as if it were an on-demand task call arriving at your application's endpoint.</p> <pre><code>sequenceDiagram\n    autonumber\n    participant User\n    participant ManagementCmd as \"manage.py schedule_tasks\"\n    participant DjangoApp as \"Django Application\"\n    participant CloudScheduler as \"Google Cloud Scheduler\"\n    participant TaskEndpoint as \"Task Execution URL (in DjangoApp)\"\n\n    User-&gt;&gt;ManagementCmd: Executes command\n    ManagementCmd-&gt;&gt;DjangoApp: Scans for PeriodicTask classes\n    ManagementCmd-&gt;&gt;CloudScheduler: API: Create/Update Job(s)\n    CloudScheduler--&gt;&gt;ManagementCmd: Confirms Job(s) status\n    ManagementCmd--&gt;&gt;User: Outputs status ([+], [~], [-])\n\n    Note over CloudScheduler, TaskEndpoint: Later, at scheduled time...\n\n    CloudScheduler-&gt;&gt;TaskEndpoint: HTTP POST (with payload, OIDC/custom headers)\n    TaskEndpoint-&gt;&gt;DjangoApp: Receives request\n    DjangoApp-&gt;&gt;DjangoApp: Executes PeriodicTask.run() method\n    TaskEndpoint--&gt;&gt;CloudScheduler: HTTP 2xx (on success)</code></pre> <p>Eager Mode Behavior (<code>DJANGO_CLOUD_TASKS_EAGER = True</code>) If <code>DJANGO_CLOUD_TASKS_EAGER</code> is true, running <code>python manage.py schedule_tasks</code> will not actually interact with Google Cloud Scheduler. Instead, for any tasks that would have been added or updated, their <code>run()</code> method will be executed synchronously, locally, one time. This is primarily for testing the task logic itself, not the scheduling mechanism.</p> <p>And that's the rundown on keeping your tasks running like clockwork with scheduled tasks!</p>"},{"location":"task_field/","title":"TaskField","text":"<p>Django Cloud Tasks provides a custom Django model field, <code>django_cloud_tasks.field.TaskField</code>, designed to store a reference to a specific task class name within your models.</p> <p>This is particularly useful when you want to dynamically determine which task to run based on a model instance's data.</p>"},{"location":"task_field/#overview","title":"Overview","text":"<p>The <code>TaskField</code> is a subclass of Django's <code>CharField</code>. It stores the string representation of a task class (e.g., <code>\"MyCoolTask\"</code> or <code>\"myapp.tasks.AnotherTask\"</code> if it's not auto-discoverable by simple name).</p> <p>Key features:</p> <ul> <li>Validation: It can automatically validate that the stored string corresponds to an actual task class registered with Django Cloud Tasks.</li> <li>Convenient Class Access: It dynamically adds a property to your model that allows you to directly access the task class itself from the stored name.</li> </ul>"},{"location":"task_field/#usage","title":"Usage","text":"<p>Here's how you might use <code>TaskField</code> in one of your models:</p> <p>models.py<pre><code>from django.db import models\nfrom django_cloud_tasks.field import TaskField\n\nclass NotificationRule(models.Model):\n    name = models.CharField(max_length=100)\n    event_type = models.CharField(max_length=50, unique=True)\n\n    task_to_run_name = TaskField() # (1)!\n\n    is_active = models.BooleanField(default=True)\n\n    def trigger_action(self, payload: dict):\n        if self.is_active and self.task_to_run_name:\n            ActualTaskClass = self.task_to_run_class # (2)!\n            if ActualTaskClass:\n                print(f\"Triggering task {ActualTaskClass.name()} for event {self.event_type}\")\n                ActualTaskClass.asap(**payload)\n            else:\n                print(f\"No valid task class found for {self.task_to_run_name}\")\n</code></pre> 1.  Stores the name of the task to execute for this event type.     You can use <code>validate_task=False</code> to skip validation at the DB level (e.g., during migrations before tasks are loaded). 2.  Access the actual task class via the dynamically added property. If your field is <code>foo_name</code>, the property is <code>foo_class</code>.</p>"},{"location":"task_field/#field-options","title":"Field Options","text":"<ul> <li><code>validate_task: bool = True</code><ul> <li>If <code>True</code> (default), the field will validate that the provided task name corresponds to a registered task class when the value is being prepared for the database. This helps ensure data integrity.</li> <li>If <code>False</code>, this validation is skipped. This might be useful in scenarios like during initial data migrations where tasks might not be fully loaded or discoverable yet.</li> </ul> </li> <li><code>max_length: int = 50</code><ul> <li>The default <code>max_length</code> for the underlying <code>CharField</code>. You can override this if your task names are longer (though 50 characters is usually sufficient for a class name).</li> </ul> </li> <li>Other <code>CharField</code> options (like <code>null</code>, <code>blank</code>, <code>default</code>, <code>help_text</code>, etc.) can also be used.</li> </ul>"},{"location":"task_field/#how-the-class-property-works","title":"How the Class Property Works","text":"<p>When you define a field like <code>my_task_field_name = TaskField()</code>, the <code>TaskField</code> automatically adds a new property to your model named <code>my_task_field_class</code>.</p> <p>So, if your field is <code>task_to_run_name</code>, the property becomes <code>task_to_run_class</code>. If your field is <code>backup_task_name</code>, the property becomes <code>backup_task_class</code>.</p> <p>This makes it very convenient to work with, as you can directly call class methods like <code>.asap()</code>, <code>.sync()</code>, or <code>.later()</code> on the retrieved class.</p>"},{"location":"task_field/#use-cases","title":"Use Cases","text":"<ul> <li>Configurable Workflows: Allow administrators or users to select different tasks for different events or conditions through a Django admin interface or a settings model.</li> <li>Dynamic Task Routing: In a system that processes various types of jobs, a model instance can hold a reference to the specific task class responsible for handling its job type.</li> <li>Scheduled Task Management: If you have a model that defines custom schedules, it could also store the name of the task to be executed on that schedule.</li> </ul> <p><code>TaskField</code> simplifies storing and retrieving task references in your database, adding a layer of validation and convenience.</p>"}]}